{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "NLTK is a toolkit build for working with NLP in Python. It provides us various text processing libraries.\n",
    "#### Text Processing steps:\n",
    "1.Tokenization\n",
    "2.Lower case conversion\n",
    "3.Stop Words removal\n",
    "4.Stemming\n",
    "5.Lemmatization\n",
    "6.Parse tree or Syntax Tree generation\n",
    "7.POS Tagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Tokenization \n",
    "The breaking down of text into smaller units is called tokens. tokens are a small part of that text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Text preprocessing is a method to clean the text data and make it ready to feed data to the model.', 'Text data contains noise in various forms like emotions, punctuation, text in a different case.', 'When we talk about Human Language then, there are different ways to say the same thing, And this is only the main problem we have to deal with because machines will not understand words, they need numbers so we need to convert text to numbers in an efficient manner']\n",
      "['Text', 'preprocessing', 'is', 'a', 'method', 'to', 'clean', 'the', 'text', 'data', 'and', 'make', 'it', 'ready', 'to', 'feed', 'data', 'to', 'the', 'model', '.', 'Text', 'data', 'contains', 'noise', 'in', 'various', 'forms', 'like', 'emotions', ',', 'punctuation', ',', 'text', 'in', 'a', 'different', 'case', '.', 'When', 'we', 'talk', 'about', 'Human', 'Language', 'then', ',', 'there', 'are', 'different', 'ways', 'to', 'say', 'the', 'same', 'thing', ',', 'And', 'this', 'is', 'only', 'the', 'main', 'problem', 'we', 'have', 'to', 'deal', 'with', 'because', 'machines', 'will', 'not', 'understand', 'words', ',', 'they', 'need', 'numbers', 'so', 'we', 'need', 'to', 'convert', 'text', 'to', 'numbers', 'in', 'an', 'efficient', 'manner']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\antuh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "\n",
    "text = \"Text preprocessing is a method to clean the text data and make it ready to feed data to the model. Text data contains noise in various forms like emotions, punctuation, text in a different case. When we talk about Human Language then, there are different ways to say the same thing, And this is only the main problem we have to deal with because machines will not understand words, they need numbers so we need to convert text to numbers in an efficient manner\"\n",
    "\n",
    "print(sent_tokenize(text))\n",
    "print(word_tokenize(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Lower Case Conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['text', 'preprocessing', 'is', 'a', 'method', 'to', 'clean', 'the', 'text', 'data', 'and', 'make', 'it', 'ready', 'to', 'feed', 'data', 'to', 'the', 'model', 'text', 'data', 'contains', 'noise', 'in', 'various', 'forms', 'like', 'emotions', 'punctuation', 'text', 'in', 'a', 'different', 'case', 'when', 'we', 'talk', 'about', 'human', 'language', 'then', 'there', 'are', 'different', 'ways', 'to', 'say', 'the', 'same', 'thing', 'and', 'this', 'is', 'only', 'the', 'main', 'problem', 'we', 'have', 'to', 'deal', 'with', 'because', 'machines', 'will', 'not', 'understand', 'words', 'they', 'need', 'numbers', 'so', 'we', 'need', 'to', 'convert', 'text', 'to', 'numbers', 'in', 'an', 'efficient', 'manner']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "text = re.sub(r\"[^a-zA-Z0-9]\", \" \", text.lower())\n",
    "words = text.split()\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.Stop Words removal:  \n",
    "Stopwords are common words like “the,” “is,” and “and” that often occur frequently but convey little semantic meaning. Removing stopwords can improve the efficiency of text analysis by reducing noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\antuh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "print(stopwords.words(\"english\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['text', 'preprocessing', 'method', 'clean', 'text', 'data', 'make', 'ready', 'feed', 'data', 'model', 'text', 'data', 'contains', 'noise', 'various', 'forms', 'like', 'emotions', 'punctuation', 'text', 'different', 'case', 'talk', 'human', 'language', 'different', 'ways', 'say', 'thing', 'main', 'problem', 'deal', 'machines', 'understand', 'words', 'need', 'numbers', 'need', 'convert', 'text', 'numbers', 'efficient', 'manner']\n"
     ]
    }
   ],
   "source": [
    "filtered_words = [w for w in words if w.lower() not in stopwords.words('english')]\n",
    "\n",
    "print(filtered_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.Stemming:\n",
    "In our text we may find many words like playing, played, playfully, etc… which have a root word, play all of these convey the same meaning. So we can just extract the root word and remove the rest. Here the root word formed is called ‘stem’ and it is not necessarily that stem needs to exist and have a meaning. Just by committing the suffix and prefix, we generate the stems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['text', 'preprocess', 'is', 'a', 'method', 'to', 'clean', 'the', 'text', 'data', 'and', 'make', 'it', 'readi', 'to', 'feed', 'data', 'to', 'the', 'model', 'text', 'data', 'contain', 'nois', 'in', 'variou', 'form', 'like', 'emot', 'punctuat', 'text', 'in', 'a', 'differ', 'case', 'when', 'we', 'talk', 'about', 'human', 'languag', 'then', 'there', 'are', 'differ', 'way', 'to', 'say', 'the', 'same', 'thing', 'and', 'thi', 'is', 'onli', 'the', 'main', 'problem', 'we', 'have', 'to', 'deal', 'with', 'becaus', 'machin', 'will', 'not', 'understand', 'word', 'they', 'need', 'number', 'so', 'we', 'need', 'to', 'convert', 'text', 'to', 'number', 'in', 'an', 'effici', 'manner']\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem.porter import PorterStemmer\n",
    "# Reduce words to their stems\n",
    "stemmed = [PorterStemmer().stem(w) for w in words]\n",
    "print(stemmed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Lemmatization\n",
    "It stems from the word but ensures it does not lose meaning.  Lemmatization has a pre-defined dictionary that stores the context of words and checks the word in the dictionary while diminishing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\antuh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['text', 'preprocessing', 'is', 'a', 'method', 'to', 'clean', 'the', 'text', 'data', 'and', 'make', 'it', 'ready', 'to', 'feed', 'data', 'to', 'the', 'model', 'text', 'data', 'contains', 'noise', 'in', 'various', 'form', 'like', 'emotion', 'punctuation', 'text', 'in', 'a', 'different', 'case', 'when', 'we', 'talk', 'about', 'human', 'language', 'then', 'there', 'are', 'different', 'way', 'to', 'say', 'the', 'same', 'thing', 'and', 'this', 'is', 'only', 'the', 'main', 'problem', 'we', 'have', 'to', 'deal', 'with', 'because', 'machine', 'will', 'not', 'understand', 'word', 'they', 'need', 'number', 'so', 'we', 'need', 'to', 'convert', 'text', 'to', 'number', 'in', 'an', 'efficient', 'manner']\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "# Reduce words to their root form\n",
    "lemmed = [WordNetLemmatizer().lemmatize(w) for w in words]\n",
    "print(lemmed)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
